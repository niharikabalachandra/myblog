<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>My Blog</title>
<link>https://www.niharikabalachandra.com/</link>
<atom:link href="https://www.niharikabalachandra.com/index.xml" rel="self" type="application/rss+xml"/>
<description>Niharika&#39;s blog where data points weave stories, and algorithmic solutions propel us toward a clearer, more informed future. </description>
<generator>quarto-1.4.549</generator>
<lastBuildDate>Sat, 03 Feb 2024 08:00:00 GMT</lastBuildDate>
<item>
  <title>Image Recognition Engine with GenAI Explanation</title>
  <dc:creator>Niharika Balachandra</dc:creator>
  <link>https://www.niharikabalachandra.com/posts/image_recognition/</link>
  <description><![CDATA[ 





<section id="the-deployed-application" class="level1">
<h1>The Deployed Application</h1>
<iframe src="https://niharikabalachandra-find-and-explain-flowers-streamlit.hf.space" frameborder="0" width="850" height="450">
</iframe>
</section>
<section id="introduction-unpacking-the-application" class="level1">
<h1>Introduction: Unpacking the Application</h1>
<p>I wanted to develop an Image Recognition Engine that not only identifies images but also offers an initial explanation of the recognized image using an open-source, large language model. The ultimate goal was to create a self-contained application that goes beyond image recognition and also serves as a starting point to gain an understanding of what an identified image is all about.</p>
<p>This particular application shown above focuses on recognition of flowers and is based on the <a href="https://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html">102 Category Flower Dataset</a></p>
<p>There are 3 main components to the app and I explain each component in more detail in the following sections: - Image Recognition - Generating Image Explanation via LLM - Streamlit Application</p>
</section>
<section id="image-recognition" class="level1">
<h1>Image Recognition</h1>
<section id="model-tuning" class="level2">
<h2 class="anchored" data-anchor-id="model-tuning">Model Tuning</h2>
<p>The idea is to use transfer learning to fine tune a pre-trained vision model. I use the Resnet50 pre-trained model for this project but there a host of other pre-trained vision models you can find via <a href="https://github.com/huggingface/pytorch-image-models?tab=readme-ov-file#models">pytorch-image-models or timm</a>. The easiest way to fine tune the Resnet50 pre-trained model is using the <a href="https://timm.fast.ai/#Fine-tune-timm-model-in-fastai">fastai library</a>. Here is the <a href="https://www.kaggle.com/code/niharikabalachandra/flowerdetector-oxford-102-flowers">notebook</a> I used to generate a pickled version of the finetuned model.</p>
</section>
<section id="deploying-on-hugging-face" class="level2">
<h2 class="anchored" data-anchor-id="deploying-on-hugging-face">Deploying on Hugging Face</h2>
<p>We now needed to host this serialized model on Hugging Face and interact with it via the huggingface_hub python library. Uploading a model to hugging face is really simple via the UI and this <a href="https://huggingface.co/docs/hub/en/models-uploading#using-the-web-interface">doc</a> walks though the process in detail. The following code can then be used to load this hosted model into memory so we can build the app around it.</p>
<div id="8088deb7" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> huggingface_hub <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> hf_hub_download</span>
<span id="cb1-2"></span>
<span id="cb1-3">REPO_ID <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"username/huggingface_repo"</span></span>
<span id="cb1-4">FILENAME <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"export.pkl"</span></span>
<span id="cb1-5"></span>
<span id="cb1-6">model_file_name <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> hf_hub_download(repo_id<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>REPO_ID, filename<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>FILENAME)</span></code></pre></div>
</details>
</div>
</section>
<section id="architecture" class="level2">
<h2 class="anchored" data-anchor-id="architecture">Architecture</h2>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">---
title: Model Fine-tuning
---
flowchart LR
  A(Resnet50 Pre-trained Model) --&gt; B(Fine-tuned for Indentification of Flowers)
  B --&gt; C(Serialized Model)
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">---
title: Deploying Model on Hugging Face 
---
flowchart LR
 C(Serialized Fine-tuned Model) --&gt; D(Host Serialized Model on Hugging Face)
D --&gt; E(Load Model as needed)
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
</section>
<section id="generating-image-explanation-via-llm" class="level1">
<h1>Generating Image Explanation via LLM</h1>
<section id="deploying-quantized-llm-on-hugging-face" class="level2">
<h2 class="anchored" data-anchor-id="deploying-quantized-llm-on-hugging-face">Deploying Quantized LLM on Hugging Face</h2>
<p>The idea here is to host a dockerized version of a quantized open source LLM using the CPU tier on Hugging Face Spaces and exposing the LLM via an API endpoint for us to then be able to interact with for free. I chose to use <a href="https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha">Zephyr 7B Alpha</a> which is a fine-tuned version of Mistral AIâ€™s <a href="mistralai/Mistral-7B-v0.1">Mistral-7B-v0.1</a>.</p>
<p>My implementation of this step is inspired by this <a href="https://gathnex.medium.com/how-to-deploy-llm-for-free-of-cost-6e7947d9b64a">blog post</a> that goes over the exact process of getting to an API endpoint.</p>
</section>
<section id="architecture-1" class="level2">
<h2 class="anchored" data-anchor-id="architecture-1">Architecture</h2>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">---
title: Deploying Quantized LLM on Hugging Face
---
flowchart LR
C(FastAPI Function for LLM completion) --&gt; D(Containerize our Application)
D --&gt; E(Deploy via Hugging Face Spaces)
E --&gt; F(Fast API Endpoint)
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
</section>
<section id="streamlit-application" class="level1">
<h1>Streamlit Application</h1>
<section id="deploying-streamlit-application-on-hugging-face-spaces" class="level2">
<h2 class="anchored" data-anchor-id="deploying-streamlit-application-on-hugging-face-spaces">Deploying Streamlit Application on Hugging Face Spaces</h2>
<p>I start with creating a new <a href="https://huggingface.co/docs/hub/en/spaces-sdks-streamlit#create-a-new-streamlit-space">Streamlit Hugging Face Space</a>. I then build the streamlit app that integrates all the 3 components: load in the image recognition model, build out the interface to upload images and display results and finally to pass the prediction via a prompt to generate a high-level explanation of the flower species identified. You can refer to the <a href="https://huggingface.co/spaces/niharikabalachandra/find_and_explain_flowers_streamlit/blob/main/app.py">app.py</a> file for more information.</p>
</section>
<section id="architecture-2" class="level2">
<h2 class="anchored" data-anchor-id="architecture-2">Architecture</h2>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">---
title: Streamlit Application on Hugging Space Spaces
---
flowchart LR

D(Build App User Interface)
D --&gt; B(Upload Flower Image)
D --&gt; C(Load Image Recognition Model)
B --&gt; C
C --&gt; E{Identify Flower Species}
E --&gt; N(Output Identified Flower Species)

E --&gt; F(Pass Identified Label to LLM)
F --&gt; G(Generate LLM Response)
G --&gt; O(Ouput Response on Identified Flower Species)
O --&gt; D
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
</section>
<section id="reference" class="level1">
<h1>Reference</h1>
<section id="model-tuning-image-recognition" class="level4">
<h4 class="anchored" data-anchor-id="model-tuning-image-recognition">Model tuning | Image Recognition</h4>
<ul>
<li>My approach was insipred by this kaggle <a href="https://www.kaggle.com/code/hobaak/flowerdetector-oxford-102-flowers">notebook</a></li>
</ul>
</section>
<section id="deploying-quantized-llm-on-hugging-face-generating-image-explanation-via-llm" class="level4">
<h4 class="anchored" data-anchor-id="deploying-quantized-llm-on-hugging-face-generating-image-explanation-via-llm">Deploying Quantized LLM on Hugging Face | Generating Image Explanation via LLM</h4>
<ul>
<li>The <a href="https://gathnex.medium.com/how-to-deploy-llm-for-free-of-cost-6e7947d9b64a">blog post</a> that goes over the exact process of getting to an API endpoint</li>
</ul>


</section>
</section>

 ]]></description>
  <category>code</category>
  <category>analysis</category>
  <category>deploy</category>
  <guid>https://www.niharikabalachandra.com/posts/image_recognition/</guid>
  <pubDate>Sat, 03 Feb 2024 08:00:00 GMT</pubDate>
  <media:content url="https://www.niharikabalachandra.com/posts/image_recognition/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Welcome To My Blog</title>
  <dc:creator>Niharika Balachandra</dc:creator>
  <link>https://www.niharikabalachandra.com/posts/welcome/</link>
  <description><![CDATA[ 
<div class="page-columns page-rows-contents page-layout-article"><div class="social-share"><a href="https://twitter.com/share?url=https://niharikabalachandra.com/posts/welcome/&amp;text=Welcome to my blog!" target="_blank" class="twitter"><i class="fab fa-twitter fa-fw fa-lg"></i></a><a href="https://www.linkedin.com/shareArticle?url=https://niharikabalachandra.com/posts/welcome/&amp;title=Welcome to my blog!" target="_blank" class="linkedin"><i class="fa-brands fa-linkedin-in fa-fw fa-lg"></i></a>  <a href="mailto:?subject=Welcome to my blog!&amp;body=Check out this link:https://niharikabalachandra.com/posts/welcome/" target="_blank" class="email"><i class="fa-solid fa-envelope fa-fw fa-lg"></i></a><a href="https://www.facebook.com/sharer.php?u=https://niharikabalachandra.com/posts/welcome/" target="_blank" class="facebook"><i class="fab fa-facebook-f fa-fw fa-lg"></i></a><a href="https://reddit.com/submit?url=https://niharikabalachandra.com/posts/welcome/&amp;title=Welcome to my blog!" target="_blank" class="reddit">   <i class="fa-brands fa-reddit-alien fa-fw fa-lg"></i></a></div></div>





<p>Welcome to my blog! Iâ€™m Niharika, a passionate data scientist weaving together data, tech, and creativity. Over seven years, Iâ€™ve led teams in ML, NLP, and beyond, transforming data into actionable insights for user-centric solutions in E-commerce and Ad Tech.</p>
<p>But, letâ€™s make this journey about us. Follow along as I navigate the ever-changing and sometimes overwhelming world of AI through applied projects. This space is meant to be sharedâ€”a place to connect and learn together.</p>
<p>Expect bi-monthly posts on every 2nd and 4th Saturday. Without further ado, join me on a journey where data tells stories, and together, we explore the algorithms actively shaping our future. Letâ€™s connect and delve into this exciting space!</p>
<p>If this labor of love enriches your life, please consider supporting it with a <a href="https://www.buymeacoffee.com/niharikaba1" class="external" target="_blank">donation</a>. Your contributions have a real impact, enabling me to curate content that demystifies the rapidly changing world of AI, fostering innovation and creating a community. This is a passion project I pursue during my free time, and I aim to keep it free, ad-free, and alive thanks to reader patronage. If you already donate, I appreciate you more than you know.</p>



 ]]></description>
  <category>news</category>
  <guid>https://www.niharikabalachandra.com/posts/welcome/</guid>
  <pubDate>Sun, 28 Jan 2024 08:00:00 GMT</pubDate>
  <media:content url="https://www.niharikabalachandra.com/posts/welcome/thumbnail.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
